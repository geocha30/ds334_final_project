---
title: "Predicting Growth Potential for Under-Developed Countries in the World Using Neural Networks"
author: "George Charalambous"
execute: 
  warning: false
format:
  html:
    embed-resources: true
    table-of-contents: true
---

## Introduction

This project could represent the minimal work conducted on underdeveloped countries and answer the question if there is sufficient data out there regarding underdeveloped countries, with the answer being a loud "NO". Being an intern with the Sub-Saharan Africa Poverty Team with the World Bank Group last summer, I realized that the lack of data regarding underdeveloped countries is something that needs to be addressed. This insufficient provision of data does not allow extensive research to be conducted and therefore lead to detailed solutions. 

The purpose of this project is to "effectively" construct a classification model for underdeveloped countries, given a set of variables from [The World Bank Data Repository](https://data.worldbank.org/indicator). The initial selection of variables was indeed challenging, since most data sets would not contain enough data for underdeveloped countries, with `NA` values overwhelming the corresponding rows. Because of that, I decided to focus on the 21st century and ignore data before the year 2000. Two primary analytical approaches employed in this project are: logistic regression and neural networks.

Logistic regression, a classical statistical method, is utilized to model the probability of a country being classified as underdeveloped based on its socio-economic indicators. By fitting a logistic regression model to the data, the project seeks to identify the key variables that significantly influence a country's development status. This approach provides interpretable results and insights into the relative importance of different indicators.

In addition to logistic regression, the project also explores the application of neural networks, a more advanced machine learning technique. Neural networks offer the advantage of capturing complex, nonlinear relationships between predictors and the response variable. By designing and training neural network models, the project aims to uncover nuanced patterns and interactions within the data that may not be captured by traditional linear models like logistic regression.

## Load the Materials

```{r}
library(tidyverse)
library(here)
library(maps)
library(plotly)
library(broom)
library(colorspace)
world_df <- map_data("world")
```

```{r}
electricity_access <- read_csv("data/access_to_electricity/access_to_electricity.csv", 
                        skip = 4) |>
  select(-c(3:44), -c(67:69))
```

```{r}
countries <- c("Afghanistan", "Angola", "Bangladesh", "Benin", "Burkina Faso", "Burundi", "Cambodia", "Central African Republic", "Chad", "Comoros", "Congo, Dem. Rep.", "Djibouti", "Eritrea", "Ethiopia", "Gambia, The", "Guinea", "Guinea-Bissau", "Haiti", "Kiribati", "Lao PDR", "Lesotho", "Liberia", "Madagascar", "Malawi", "Mali", "Mauritania", "Mozambique", "Myanmar", "Nepal", "Niger", "Rwanda", "Sao Tome and Principe", "Senegal", "Sierra Leone", "Solomon Islands", "Somalia", "South Sudan", "Sudan", "Tanzania", "Timor-Leste", "Togo", "Tuvalu", "Uganda", "Yemen, Rep.", "Zambia")
```

```{r}
electricity_stats <- electricity_access |>
  pivot_longer(c(3:24), 
               names_to = "Year", 
               values_to = "Electricity Access") |>
  filter(!is.na(`Electricity Access`)) |>
  group_by(`Country Name`) |>
  summarise(`mean_elec_access` = mean(`Electricity Access`, na.rm = TRUE),
            `sd_elec_access` = sd(`Electricity Access`, na.rm = TRUE))
```

```{r}
#| output: false
underdeveloped_electricity <- electricity_access |>
  pivot_longer(c(3:24), 
               names_to = "Year", 
               values_to = "Electricity Access") |>
  filter(!is.na(`Electricity Access`)) 
```

```{r}
#| output: false
underdeveloped_map <- left_join(underdeveloped_electricity, world_df, by = c("Country Name"="region"))
```

```{r}
#| output: false
plot_1 <- ggplot()+
  geom_polygon(data = world_df, mapping = aes(x = long, y = lat, group = group, label = region), fill = "grey")+
  geom_polygon(data = underdeveloped_map, mapping = aes(x = long, y = lat, group = group, fill = `Electricity Access`, label = `Country Name`))+
  scale_fill_continuous_sequential(palette = "Heat")+
  theme_minimal()

ggplotly(plot_1, tooltip = "label")
```

```{r}
agricultural_land <- read_csv("data/agricultural_land/agricultural_land.csv", 
                       skip = 4) |>
  select(-c(3:44), -c(67:69))
```

```{r}
agriculture_land_stats <- agricultural_land |>
  pivot_longer(c(3:24), 
               names_to = "Year", 
               values_to = "Agricultural Land") |>
  filter(!is.na(`Agricultural Land`)) |>
  group_by(`Country Name`) |>
  summarise(`mean_agr_land` = mean(`Agricultural Land`, na.rm = TRUE),
            `sd_agr_land` = sd(`Agricultural Land`, na.rm = TRUE))
```

```{r}
population_growth <- read_csv("~/Desktop/Sixth Semester/ds334_final_project/ds334_final_project/data/population_growth_annual/population_growth.csv", 
                            skip = 4) |>
  select(-c(3:44), -c(67:69))
```

```{r}
population_growth_stats <- population_growth |>
  pivot_longer(c(3:24), 
               names_to = "Year", 
               values_to = "Population Growth Rate") |>
  filter(!is.na(`Population Growth Rate`)) |>
  group_by(`Country Name`) |>
  summarise(`mean_pop_growth` = mean(`Population Growth Rate`, na.rm = TRUE),
            `sd_pop_growth` = sd(`Population Growth Rate`, na.rm = TRUE))
```

```{r}
primary_school_enrol <- read_csv("~/Desktop/Sixth Semester/ds334_final_project/ds334_final_project/data/primary_school_enrollment/primary_school.csv", 
          skip = 4) |>
  select(-c(3:44), -c(67:69))
```

```{r}
primary_school_enrol_stats <- primary_school_enrol |>
  pivot_longer(c(3:24), 
               names_to = "Year", 
               values_to = "Primary School Enrollment Rate") |>
  filter(!is.na(`Primary School Enrollment Rate`)) |>
  group_by(`Country Name`) |>
  summarise(`mean_prim_school` = mean(`Primary School Enrollment Rate`, na.rm = TRUE),
            `sd_prim_school` = sd(`Primary School Enrollment Rate`,na.rm = TRUE))
```

```{r}
total_unemployment <- read_csv("~/Desktop/Sixth Semester/ds334_final_project/ds334_final_project/data/total_unemployment/total_unemployment.csv", 
          skip = 4) |>
  select(-c(3:44), -c(67:69))
```

```{r}
total_unemployment_stats <- total_unemployment |>
  pivot_longer(c(3:24), 
               names_to = "Year", 
               values_to = "Total Unemployment") |>
  filter(!is.na(`Total Unemployment`)) |>
  group_by(`Country Name`) |>
  summarise(`mean_total_unempl` = mean(`Total Unemployment`, na.rm = TRUE),
            `sd_total_unempl` = sd(`Total Unemployment`, na.rm = TRUE))
```

```{r}
sanitation <- read_csv("data/basic_sanitation_services/basic_sanitation.csv", 
          skip = 4) |>
  select(-c(3:44), -c(67:69))
```

```{r}
sanitation_stats <- sanitation |>
  pivot_longer(c(3:24), 
               names_to = "Year", 
               values_to = "Sanitation") |>
  filter(!is.na(`Sanitation`)) |>
  group_by(`Country Name`) |>
  summarise(`mean_sanit` = mean(`Sanitation`, na.rm = TRUE),
            `sd_sanit` = sd(`Sanitation`, na.rm = TRUE))
```

```{r}
fertility_rate <- read_csv("data/fertility_rate/fertility_rate.csv", 
          skip = 4) |>
  select(-c(3:44), -c(67:69))
```

```{r}
fertility_rate_stats <- fertility_rate |>
  pivot_longer(c(3:24), 
               names_to = "Year", 
               values_to = "Fertility Rate") |>
  filter(!is.na(`Fertility Rate`)) |>
  group_by(`Country Name`) |>
  summarise(`mean_fert_rate` = mean(`Fertility Rate`, na.rm = TRUE),
            `sd_fert_rate` = sd(`Fertility Rate`, na.rm = TRUE))
```

```{r}
internet <- read_csv("data/internet/internet.csv", 
          skip = 4) |>
  select(-c(3:44), -c(67:69))
```

```{r}
internet_stats <- internet |>
  pivot_longer(c(3:24), 
               names_to = "Year", 
               values_to = "Internet") |>
  filter(!is.na(`Internet`)) |>
  group_by(`Country Name`) |>
  summarise(`mean_inter` = mean(`Internet`, na.rm = TRUE),
            `sd_inter` = sd(`Internet`, na.rm = TRUE))
```

```{r}
birth_life_exp <- read_csv("data/life_expectancy_birth/life_expectancy_birth.csv", 
          skip = 4) |>
  select(-c(3:44), -c(67:69))
```

```{r}
birth_life_exp_stats <- birth_life_exp |>
  pivot_longer(c(3:24), 
               names_to = "Year", 
               values_to = "Life Expectancy at Birth") |>
  filter(!is.na(`Life Expectancy at Birth`)) |>
  group_by(`Country Name`) |>
  summarise(`mean_life_exp` = mean(`Life Expectancy at Birth`, na.rm = TRUE),
            `sd_life_exp` = sd(`Life Expectancy at Birth`, na.rm = TRUE))
```

```{r}
full_stats_df <- agriculture_land_stats |>
  left_join(birth_life_exp_stats, by = "Country Name") |>
  left_join(electricity_stats, by = "Country Name") |>
  left_join(fertility_rate_stats, by = "Country Name") |>
  left_join(internet_stats, by = "Country Name") |>
  left_join(sanitation_stats, by = "Country Name") |>
  left_join(population_growth_stats, by = "Country Name") |>
  left_join(primary_school_enrol_stats, by = "Country Name") |>
  left_join(total_unemployment_stats, by = "Country Name") 
```

```{r}
full_stats_df <- 
  full_stats_df |>
  mutate(Underdeveloped = ifelse(`Country Name` %in% countries, 1, 0))
```

## Variable Description

| Variable | Description
|----------|----------------------------------------
| agriculture_land | The share of land area that is arable, under permanent crops, and under permanent pastures |
| birth_life_exp | The number of years a newborn infant would live if prevailing patterns of mortality at the time of its birth were to stay the same throughout its life |
| electricity_access | The percentage of population with access to electricity |
| fertility_rate | The number of children that would be born to a woman if she were to live to the end of her childbearing years and bear children in accordance with age-specific fertility rates of the specified year |
| internet | The percentage of population that uses the internet |
| population_growth | Annual population growth rate for year t is the exponential rate of growth of midyear population from year t-1 to t, expressed as a percentage |
| primary_school_enrol | Gross enrollment ratio is the ratio of total enrollment, regardless of age, to the population of the age group that officially corresponds to the level of education shown |
| sanitation | Percentage of people using at least basic sanitation services, that is, improved sanitation facilities that are not shared with other households |
| total_unemployment | The share of the labor force that is without work but available for and seeking employment |

## Data Set Investigation

```{r}
library(GGally)
ggpairs(data = full_stats_df, columns = c(2, 4, 6, 8, 10, 12, 14, 16, 18))
```

#### Logistic Regression Model Attempt

```{r}
# Get the means column for each variable
# Preprocess the data
full_means_df <- full_stats_df |>
  select(contains("mean"))

# Subset the data frame to only numeric columns
numeric_columns <- sapply(full_means_df, is.numeric)

# Scale the data
scaled_data <- scale(full_means_df[, numeric_columns])

# Add the "Underdeveloped" column back to the scaled data
scaled_data_with_undev <- scaled_data |>
  as.data.frame() |>
  mutate(Underdeveloped = full_stats_df$Underdeveloped) |>
  na.omit()
```

```{r}
median_agr_land = median(scaled_data_with_undev$mean_agr_land, na.rm = TRUE)
median_life_exp = median(scaled_data_with_undev$mean_life_exp, na.rm = TRUE)
median_elec_access = median(scaled_data_with_undev$mean_elec_access, na.rm = TRUE)
median_fert_rate = median(scaled_data_with_undev$mean_fert_rate, na.rm = TRUE)
median_sanit = median(scaled_data_with_undev$mean_sanit, na.rm = TRUE)
median_population_growth = median(scaled_data_with_undev$mean_pop_growth, na.rm = TRUE)
median_primary_school = median(scaled_data_with_undev$mean_prim_school, na.rm = TRUE)
median_total_unempl = median(scaled_data_with_undev$mean_total_unempl, na.rm = TRUE)
median_internet = median(scaled_data_with_undev$mean_inter, na.rm = TRUE)
```

```{r}
library(modelr)
## First Attempt
# Fit the logistic regression model with all the variables
model_glm <- glm(Underdeveloped ~ .,
                  data = scaled_data_with_undev, family = "binomial")

# Check the summary of the model
summary(model_glm)
```

```{r}
# Identify numeric columns
numeric_cols <- sapply(scaled_data_with_undev, is.numeric)

# Compute range for each numeric column, removing NA values
ranges <- sapply(scaled_data_with_undev[, numeric_cols], function(x) {
  x <- na.omit(x)
  c(min(x), max(x))
})
```

```{r}
underdeveloped <- scaled_data_with_undev |>
  filter(Underdeveloped == 1)
```

```{r}
developed <- scaled_data_with_undev |>
  filter(Underdeveloped != 1) 
```

```{r}
## Second Attempt
# Fit the logistic regression model with selected variables using their range and the median for the rest
# Used the first model to come up with the most "significant" ones

model_glm <- glm(Underdeveloped ~ .,
                  data = scaled_data_with_undev, family = "binomial")

# Create the grid for prediction
grid <- full_stats_df |>
  data_grid(
    mean_agr_land = median_agr_land,
    mean_life_exp = seq_range(c(-2.627905, 1.588857), n = 3),
    mean_elec_access = seq_range(c(-2.6785616, 0.7295024), n = 3),
    mean_fert_rate = seq_range(c(-1.274220, 3.082338), n = 3),
    mean_sanit = median_sanit, 
    mean_inter = median_internet,
    mean_pop_growth = median_population_growth,
    mean_prim_school = median_primary_school, 
    mean_total_unempl = median_total_unempl
  )

# Predict probabilities that a country is Underdeveloped
aug_model <- augment(model_glm, newdata = grid, se_fit = TRUE) |>
  mutate(.predprob = plogis(.fitted))

# Visualize the predictions
ggplot(data = aug_model, aes(x = mean_fert_rate, y = .predprob)) +
  geom_line(aes(color = as.factor(round(mean_life_exp, 2)))) +
  facet_wrap(~as.factor(mean_elec_access)) +
  labs(x = "Standardized Mean Fertility Rate", y = "Predicted Probability", color = "Standardized Mean Electricity Access") +
  theme_minimal()
```

```{r}
## Third Attempt
# Fit the logistic regression model with selected variables using their range and the median for the rest
# Used the first model to include the ones that were significant but not as much

grid <- full_stats_df |>
  data_grid(
    mean_agr_land = median_agr_land,
    mean_life_exp = seq_range(c(-2.627905, 1.588857), n = 3),
    mean_elec_access = median_elec_access,
    mean_fert_rate = seq_range(c(-1.274220, 3.082338), n = 3),
    mean_sanit = median_sanit, 
    mean_inter = median_internet,
    mean_pop_growth =seq_range(c(-2.022998, 4.438928), n = 3),
    mean_prim_school = median_primary_school, 
    mean_total_unempl = median_total_unempl
  )

# Predict probabilities for the grid
aug_model <- augment(model_glm, newdata = grid, se_fit = TRUE) |>
  mutate(.predprob = plogis(.fitted))

# Visualize the predictions
ggplot(data = aug_model, aes(x = mean_fert_rate, y = .predprob)) +
  geom_line(aes(color = as.factor(round(mean_life_exp, 2)))) +
  facet_wrap(~mean_pop_growth) +
  labs(x = "Standardized Mean Fertility Rate", y = "Predicted Probability", color = "Standardized Mean Life Expectancy") +
  theme_minimal()
```

```{r}
## Forth Attempt
# Fit the logistic regression model with selected variables using their range and the median for the rest
# Used the first model to include the ones that were significant but not as much

grid <- full_stats_df |>
  data_grid(
    mean_agr_land = median_agr_land,
    mean_life_exp = median_life_exp,
    mean_elec_access = median_elec_access,
    mean_fert_rate = seq_range(c(-1.308798, 2.850897), n = 3),
    mean_sanit = median_sanit, 
    mean_inter = seq_range(c(-1.511381, 2.405766), n = 3),
    mean_pop_growth =seq_range(c(-2.221712, 3.779502), n = 3),
    mean_prim_school = median_primary_school, 
    mean_total_unempl = median_total_unempl
  )

# Predict probabilities for the grid
aug_model <- augment(model_glm, newdata = grid, se_fit = TRUE) |>
  mutate(.predprob = plogis(.fitted))

# Visualize the predictions
ggplot(data = aug_model, aes(x = mean_fert_rate, y = .predprob)) +
  geom_line(aes(color = as.factor(round(mean_inter, 2)))) +
  facet_wrap(~mean_pop_growth) +
  labs(x = "Standardized Mean Fertility Rate", y = "Predicted Probability", color = "Standardized Mean Population Growth") +
  theme_minimal()
```

In general, what we have seen from the above plots is that attempting to fit a Logistic Regression Model given different combinations of proxies does not do a good job. Therefore, a more complex model might be able to interpret the relationships between the various variables that we have. 

```{r}
library(keras)
library(tensorflow)
install_tensorflow(envname = "r-tensorflow")
```

```{r}
library(reticulate)
py_install("pandas")
```

```{r}
set.seed(123)

# Split the data into training and testing sets 80% and 20%, as we did in Machine Learning
train_indices <- sample(1:nrow(scaled_data_with_undev), 0.8 * nrow(scaled_data_with_undev))
test_indices <- setdiff(1:nrow(scaled_data_with_undev), train_indices)

train_data <- scaled_data_with_undev[train_indices, ]
test_data <- scaled_data_with_undev[test_indices, ]
```

```{r}
# Design the network
network <- keras_model_sequential() |>
  layer_dense(units = 2, activation = "relu", input_shape = c(4)) |>
  layer_dense(units = 4, activation="relu") |>
  layer_dense(units = 5, activation="relu") |>
  layer_dense(units = 4, activation="relu") |>
  layer_dense(units = 1, activation = "sigmoid")
```

```{r}
# Specify how the network will be trained
network |> compile(
  loss = "binary_crossentropy",
  metrics = c("accuracy"),
  optimizer = optimizer_adam(learning_rate = 0.01)
  ## might add regularization
)
```

```{r}
# Train the network
history <- network |> fit(
  xtrain, ytrain,
  epochs = 100,
  validation_data = list(xval, yval),
  verbose = 0
)

# Plot the learning curves
curve <- data.frame(train = history$metrics$accuracy, val = history$metrics$val_accuracy)

plot <- ggplot(data = curve, aes(x = seq_along(train))) +
  geom_line(aes(y = train, color = "Train")) +
  geom_line(aes(y = val, color = "Validation")) +
  scale_color_manual(values = c("Train" = "blue", "Validation" = "red")) +
  labs(x = "Epoch", y = "Accuracy") +
  theme_minimal()

# Evaluate the test data
network |> evaluate(xtest, ytest)

```
























